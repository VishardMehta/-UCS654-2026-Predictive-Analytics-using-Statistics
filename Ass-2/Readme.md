ğŸ“Š Sampling Techniques on Imbalanced Credit Card Dataset

ğŸ“Œ Objective

The objective of this assignment is to understand the importance of sampling techniques in handling imbalanced datasets and to analyze how different sampling strategies affect the performance of multiple machine learning models in credit card fraud detection.

â¸»

ğŸ“‚ Dataset
	â€¢	Dataset Name: Creditcard_data.csv
	â€¢	Source:
https://github.com/AnjulaMehto/Sampling_Assignment/blob/main/Creditcard_data.csv
	â€¢	Target Variable: Class
	â€¢	0 â†’ Legitimate Transaction
	â€¢	1 â†’ Fraudulent Transaction

The dataset is highly imbalanced, with fraudulent transactions being extremely rare.

â¸»

âš™ï¸ Methodology

1ï¸âƒ£ Data Preparation
	â€¢	The dataset was split into:
	â€¢	Features (X): All columns except Class
	â€¢	Target (y): Class
	â€¢	A stratified 70:30 trainâ€“test split was used to preserve class distribution.
	â€¢	Sampling techniques were applied only on the training data to prevent data leakage.

â¸»

2ï¸âƒ£ Sampling Techniques Applied

Five sampling strategies were evaluated:

Sampling ID	Technique
Sampling1	NoSampling
Sampling2	RandomOverSampler
Sampling3	RandomUnderSampler
Sampling4	SMOTE
Sampling5	SMOTETomek


â¸»

3ï¸âƒ£ Machine Learning Models

Five classifiers were trained with each sampling technique:

Model ID	Classifier
M1	Logistic Regression
M2	Decision Tree
M3	Random Forest
M4	Naive Bayes
M5	Support Vector Machine (SVM)


â¸»

4ï¸âƒ£ Evaluation Metrics

Each model was evaluated on unseen test data using:
	â€¢	Accuracy
	â€¢	Precision
	â€¢	Recall
	â€¢	F1-Score
	â€¢	ROC-AUC

âš ï¸ Since fraud detection is a cost-sensitive problem, Recall was treated as the most important metric.

â¸»

ğŸ“Š Results & Graphical Analysis

â¸»

ğŸ”¹ Accuracy Heatmap

Accuracy values appear very high for most models, even without sampling.

Observation:
	â€¢	Accuracy remains above 97% in most cases.
	â€¢	High accuracy is misleading because the majority class dominates predictions.

â¸»

ğŸ”¹ Recall Heatmap

Recall represents the ability to detect fraudulent transactions.

Key Findings:
	â€¢	NoSampling results in zero recall for most models.
	â€¢	RandomUnderSampler achieved 100% recall for Random Forest.
	â€¢	Sampling significantly improves fraud detection capability.

â¸»

ğŸ”¹ Precision Heatmap

Precision measures how many detected frauds are actually fraud.

Observation:
	â€¢	Precision decreases when recall increases.
	â€¢	This trade-off is expected in fraud detection systems.

â¸»

ğŸ”¹ F1-Score Heatmap

F1-score balances precision and recall.

Observation:
	â€¢	Best F1-score observed for Decision Tree + RandomOverSampler.
	â€¢	Many combinations show near-zero F1 due to poor recall.

â¸»

ğŸ”¹ ROC-AUC Heatmap

ROC-AUC evaluates the modelâ€™s ability to distinguish between classes.

Key Insight:
	â€¢	RandomForest + RandomUnderSampler / SMOTETomek achieved the highest ROC-AUC.
	â€¢	Random Forest shows the most stable performance across sampling techniques.

â¸»

ğŸ”¹ Average Recall per Sampling Method

This graph shows the effectiveness of each sampling method across all models.

Conclusion:
	â€¢	RandomUnderSampler provides the highest average recall.
	â€¢	RandomOverSampler also performs well.
	â€¢	SMOTE-based techniques perform moderately.

â¸»

ğŸ”¹ Best Recall per Model

This graph highlights the best sampling method for each model based on recall.

Best Combinations:
	â€¢	Logistic Regression â†’ RandomOverSampler
	â€¢	Decision Tree â†’ RandomOverSampler
	â€¢	Random Forest â†’ RandomUnderSampler
	â€¢	SVM â†’ RandomOverSampler
	â€¢	Naive Bayes â†’ Poor performance overall

â¸»

ğŸ“‹ Metrics Summary Table (Highlights)

Model	Best Sampling	Recall	ROC-AUC
Logistic Regression	RandomOverSampler	High	~0.71
Decision Tree	RandomOverSampler	High	~0.83
Random Forest	RandomUnderSampler	1.00	~0.86
SVM	RandomOverSampler	High	~0.77
Naive Bayes	None	0.00	Low

Full metrics are available in full_metrics.csv.

â¸»

âœ… Final Conclusion
	â€¢	Sampling techniques are critical when working with imbalanced datasets.
	â€¢	Accuracy alone is not reliable for fraud detection.
	â€¢	RandomUnderSampler achieved the highest recall on average.
	â€¢	RandomForest combined with RandomUnderSampler delivered the best overall performance in terms of recall and ROC-AUC.

